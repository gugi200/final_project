{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gugi200/final_project/blob/main/scikit_models_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvyDY8s_wTtF",
        "outputId": "9949fa17-7c72-4010-930c-70503ec2c64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "!wandb login 3014974e724f01c4d63f956fa13fd7f0463e16d4\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttQqYpU3rktH"
      },
      "outputs": [],
      "source": [
        "# processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ML libraries\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# torch functionality functions\n",
        "import torch\n",
        "\n",
        "# for downloading the data\n",
        "from pathlib import Path\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from sklearn.utils import Bunch\n",
        "\n",
        "# helper functions\n",
        "import wandb\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dzghromTImN"
      },
      "source": [
        "# download data for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFmXD_LjwY9q",
        "outputId": "548eca14-e605-44cf-b6be-f8865fb7b75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 16360258.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 306469.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5540179.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 16041810.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "\n",
            "creating folder\n",
            "creating folder\n"
          ]
        }
      ],
      "source": [
        "# download the test data\n",
        "\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "train_data = FashionMNIST(\n",
        "    root='~/.pytorch/F_MNIST_data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    target_transform=None)\n",
        "\n",
        "test_data = FashionMNIST(\n",
        "    root='~/.pytorch/F_MNIST_data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    target_transform=None)\n",
        "\n",
        "class_names = [x.replace('/', '_').replace('-', '') for x in train_data.classes]\n",
        "\n",
        "transform = transforms.ToPILImage()\n",
        "\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path1 = data_path / \"FashionMNIST\" / \"train\"\n",
        "\n",
        "if image_path1.is_dir():\n",
        "    print('directory already exists')\n",
        "else:\n",
        "    print('creating folder')\n",
        "    for class_name in class_names:\n",
        "        image_class_path = image_path1 / class_name\n",
        "        image_class_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for idx, (train_img, target) in enumerate(zip(train_data.data[:3000], train_data.targets[:3000])):\n",
        "        train_data_PIL = transform(train_img)\n",
        "        file = \"data_\" + str(idx) + '.jpg'\n",
        "        # print(target)\n",
        "        # print(data_path / \"FashionMNIST\"/\"train\" / class_names[target] /file)\n",
        "        train_data_PIL.save(data_path / \"FashionMNIST\"/\"train\" / class_names[target] /file)\n",
        "\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path2 = data_path / \"FashionMNIST\" / \"test\"\n",
        "if image_path2.is_dir():\n",
        "    print('directory already exists')\n",
        "else:\n",
        "    print('creating folder')\n",
        "    for class_name in class_names:\n",
        "        image_class_path = image_path2 / class_name\n",
        "        image_class_path.mkdir(parents=True, exist_ok=True)\n",
        "        image_class_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for idx, (test_img, target) in enumerate(zip(test_data.data[:250], test_data.targets[:250])):\n",
        "        test_data_PIL = transform(test_img)\n",
        "        file = \"data_\" + str(idx) + '.jpg'\n",
        "        test_data_PIL.save(data_path / \"FashionMNIST\"/\"test\" / class_names[target] /file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dataset = datasets.ImageFolder(root=Path(\"data/FashionMNIST/train\"),\n",
        "                                  transform=np.array,\n",
        "                                  target_transform=None) # transform for label\n",
        "\n",
        "\n",
        "\n",
        "class_names = dataset.classes\n",
        "\n",
        "def torch_dataset_to_numpy(dataset, target_names):\n",
        "    for i, (data, target) in enumerate(dataset):\n",
        "\n",
        "        if i==0:\n",
        "            data_numpy = data\n",
        "            data_numpy = np.expand_dims(data_numpy, axis=0)\n",
        "            target_numpy = np.array([target])\n",
        "            target_numpy = np.expand_dims(target_numpy, axis=0)\n",
        "        else:\n",
        "            data = np.expand_dims(data, axis=0)\n",
        "            target = np.expand_dims(np.array([target]), axis=0)\n",
        "            data_numpy = np.append(data_numpy, data, axis=0)\n",
        "            target_numpy = np.append(target_numpy, target, axis=0)\n",
        "\n",
        "    return Bunch(data=data_numpy, target=target_numpy, target_names=target_names)\n",
        "\n",
        "\n",
        "custom_dataset = torch_dataset_to_numpy(dataset, class_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxXRHxkaZGTq",
        "outputId": "a3e46a40-e5c8-4345-da18-c5228c20834d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "iris.data.shape, iris.target.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2W14y1hGms"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUttu9PGiXtr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDhqEJnVfxpl",
        "outputId": "4ea7992f-e362-4705-c4d4-c09d0116ac58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2250, 784), (2250, 1))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(custom_dataset.data,\n",
        "                                                    custom_dataset.target,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=42,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "\n",
        "X_train, X_test = X_train[:, :, :, 0].reshape((2250, 784)), X_test[:, :, :, 0].reshape((750, 784))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train.shape, y_train.shape\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0hCENXzPvT9"
      },
      "source": [
        "# create pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfSLpU4mPvAC",
        "outputId": "251a5ce3-f90c-4589-ec62-ba43737e2784"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random forest\n",
            "Best estimator:  RandomForestClassifier(max_depth=8, random_state=42)\n",
            "Best params:  {'max_depth': 8, 'n_estimators': 100}\n",
            "Best score:  0.8044444444444444\n",
            "decisionb forest\n",
            "Best estimator:  DecisionTreeClassifier(max_depth=8, random_state=42)\n",
            "Best params:  {'max_depth': 8}\n",
            "Best score:  0.7022222222222222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "svc standard scaler\n",
            "Best estimator:  SVC(C=2, gamma=50, probability=True)\n",
            "Best params:  {'C': 2, 'gamma': 50}\n",
            "Best score:  0.10800000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svc minmax\n",
            "Best estimator:  SVC(C=10, gamma=0.01, probability=True)\n",
            "Best params:  {'C': 10, 'gamma': 0.01}\n",
            "Best score:  0.8368888888888888\n"
          ]
        }
      ],
      "source": [
        "param_RF = {\n",
        "'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
        "'n_estimators': [50, 75, 100, 125, 150]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_RF, cv=5, n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "print('random forest')\n",
        "# print('results: ', grid_rf.cv_results_)\n",
        "print('Best estimator: ', grid_rf.best_estimator_)\n",
        "print('Best params: ', grid_rf.best_params_)\n",
        "print('Best score: ', grid_rf.best_score_)\n",
        "\n",
        "\n",
        "\n",
        "param_DT = {\n",
        "'max_depth': [2, 3, 4, 5, 6, 7, 8]\n",
        "}\n",
        "\n",
        "grid_DT = GridSearchCV(DecisionTreeClassifier(random_state=42), param_DT, cv=5, n_jobs=-1)\n",
        "grid_DT.fit(X_train, y_train)\n",
        "print('decisionb forest')\n",
        "# print('results: ', grid_DT.cv_results_)\n",
        "print('Best estimator: ', grid_DT.best_estimator_)\n",
        "print('Best params: ', grid_DT.best_params_)\n",
        "print('Best score: ', grid_DT.best_score_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "param_svc = {\n",
        "'C': [2, 3, 4, 5, 6, 7, 8],\n",
        "'gamma': [50, 75, 100, 125, 150]\n",
        "}\n",
        "\n",
        "grid_svc_std = GridSearchCV(SVC(probability=True), param_svc, cv=5, n_jobs=-1)\n",
        "stdScaled = StandardScaler()\n",
        "stdScaled = stdScaled.fit(X_train)\n",
        "scaled_X_train = stdScaled.transform(X_train)\n",
        "scaled_X_test = stdScaled.fit(X_test)\n",
        "grid_svc_std.fit(scaled_X_train, y_train)\n",
        "print('svc standard scaler')\n",
        "# print('results: ', grid_svc_std.cv_results_)\n",
        "print('Best estimator: ', grid_svc_std.best_estimator_)\n",
        "print('Best params: ', grid_svc_std.best_params_)\n",
        "print('Best score: ', grid_svc_std.best_score_)\n",
        "\n",
        "\n",
        "\n",
        "param_grid_svc = {\n",
        "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "    }\n",
        "\n",
        "\n",
        "grid_svc_mm = GridSearchCV(SVC(probability=True), param_grid_svc, cv=5, n_jobs=-1)\n",
        "mmScaled = MinMaxScaler()\n",
        "mmScaled = mmScaled.fit(X_train)\n",
        "scaled_X_train = mmScaled.transform(X_train)\n",
        "grid_svc_mm.fit(scaled_X_train, y_train)\n",
        "print('svc minmax')\n",
        "# print('results: ', grid_svc_mm.cv_results_)\n",
        "print('Best estimator: ', grid_svc_mm.best_estimator_)\n",
        "print('Best params: ', grid_svc_mm.best_params_)\n",
        "print('Best score: ', grid_svc_mm.best_score_)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo1ukVVBZj7d"
      },
      "outputs": [],
      "source": [
        "def plot_precision_recal_curve(model, y_test, X_test, title):\n",
        "    # precision, recall, threshold = precision_recall_curve(y_test, model.predict_proba(X_test))\n",
        "    # plt.figure()\n",
        "    # plt.plot(precision, recall, title='precision-recall curve ' + title)\n",
        "    # plt.xlabel('precision')\n",
        "    # plt.ylabel('recall')\n",
        "    # plt.legend(loc='best')\n",
        "\n",
        "\n",
        "    false_posR, true_posR = th = roc_curve(y_test, model.predict_proba(X_test))\n",
        "    plt.figure()\n",
        "    plt.plot(false_posR, true_posR)\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc='best')\n",
        "\n",
        "plot_precision_recal_curve(grid_rf, y_test, X_test, 'Random Forest')\n",
        "plot_precision_recal_curve(grid_DT, y_test, X_test, 'Decision Tree')\n",
        " #plot_precision_recal_curve(grid_svc_mm, y_test, X_test, 'SVC MinMax')\n",
        "# plot_precision_recal_curve(grid_svc_std, y_test. X_test, 'SVC Standard')\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJNPjk/n1rYjwuDvT25iE7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}